{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import emoji\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alg_telcom_2_2k.xlsx',\n",
       " 'facebook (1).xlsx',\n",
       " 'facebook (2).xlsx',\n",
       " 'instagram (1).xlsx',\n",
       " 'instagram (2).xlsx',\n",
       " 'instagram (3).xlsx',\n",
       " 'instagram (4).xlsx',\n",
       " 'instagram (5).xlsx',\n",
       " 'instagram (6).xlsx',\n",
       " 'instagram (7).xlsx',\n",
       " 'instagram (8).xlsx',\n",
       " 'instagram.xlsx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = ('C:/Users/BIGNETWORK/Desktop/PFE/dataset/resaux scraper')\n",
    "files = os.listdir(path)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alg_telcom_2_2k.xlsx',\n",
       " 'facebook (1).xlsx',\n",
       " 'facebook (2).xlsx',\n",
       " 'instagram (1).xlsx',\n",
       " 'instagram (2).xlsx',\n",
       " 'instagram (3).xlsx',\n",
       " 'instagram (4).xlsx',\n",
       " 'instagram (5).xlsx',\n",
       " 'instagram (6).xlsx',\n",
       " 'instagram (7).xlsx',\n",
       " 'instagram (8).xlsx',\n",
       " 'instagram.xlsx']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_xls = [f for f in files if f[-4:] == 'xlsx']\n",
    "files_xls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for f in files_xls:\n",
    "    data = pd.read_excel(f'C:/Users/BIGNETWORK/Desktop/PFE/dataset/resaux scraper/{f}')\n",
    "    data.drop(data.index[0:0],inplace=True)\n",
    "    df = df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"resaux_comments.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/resaux_comments.xlsx\")\n",
    "df1=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/hateonly_mehdi.xlsx\")\n",
    "df2=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/fb_comments.xlsx\")\n",
    "df3=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/hainer_ranim.xlsx\")\n",
    "df4=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/neutre_mehdi.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df0, df1, df2, df3,df4], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø¨Ø§ÙŠÙ†Ø© ÙƒØªØ¨ØªÙˆÙ‡Ø§ Ù†Ù‡Ø§Ø± Ø§Ù„Ø³Ø¨Øª Ø­ØªÙ‰ Ø§Ù„ÙŠÙˆÙ… Ø¨Ø§Ø´ ØªØ¨Ø§Ø±ØªØ§Ø¬...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ù„ÙˆÙƒØ§Ù† Ø³ØªÙ†ÙŠØªÙˆ Ø­ØªÙ‰ Ù†Ù‡Ø§Ø± Ø§Ù„Ø®Ù…ÙŠØ³ Ø®ÙŠØ± Ùˆ Ø¯Ø±ØªÙˆ Ø¨ÙŠØ§Ù†</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø§Ù„Ø²Ø¨ÙˆÙ† Ù„Ø§ Ø¯Ø®Ù„ Ù„Ù‡ ÙÙŠ Ø§Ù„Ø¨ÙƒØ§Ù„ÙˆØ±ÙŠØ§</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø´Ø±ÙƒØ©.... ØªØ¹Ø¬Ø² Ø¹Ù† ÙˆØ¶Ø¹ Ø£Ø¬Ù‡Ø²Ø© ØªØ´ÙˆÙŠØ´ Ø¨Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ø¥Ù…ØªØ­...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø¯ÙˆÙ…Ø§Ø¬ Ø¹Ù†Ø¯ÙŠ Ù„Ø§ÙØ§Ù…ÙŠ ÙÙŠ Ø§Ù„ÙƒÙˆÙ†Øª Ù‡Ø°Ø§ ÙƒÙˆÙ† Ø¹Ø¨Ø±ØªÙ„ÙƒÙ… Ø¹Ù†...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10076</th>\n",
       "      <td>Ø±Ø¬Ø¹ÙˆÙ„Ù†Ø§ Ø¹Ø±Ø¶ 1500Ù†ØªØ§Ø¹ 40Ø¬ÙŠØºØ§ Ø´Ù‡Ø±ÙŠÙ† Ù…Ø´ÙŠ Ø´Ù‡Ø± Ù‡ÙƒØ°Ø§...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10077</th>\n",
       "      <td>Ø§Ù†Ø¸Ø±ÙˆØ§ Ø¥Ù„Ù‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙŠØ§ Ø¯Ø¬ÙŠØ²ÙŠ Ø¨ÙÙÙÙÙÙÙÙÙÙÙÙ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>ØµØ­ Ø¹ÙŠØ¯Ùƒ Ø¬ÙŠØ²ÙŠ Ø´ÙˆÙŠ Ø§ØªÙ‡Ù„Ù‰ ÙƒÙˆÙ†ÙŠÙƒØ³ÙŠÙˆ Ø¸Ø¹ÙŠÙØ© ÙˆØ¹Ø±ÙˆØ¸ Ø´Ùˆ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>Ø¹ÙŠØ¯ÙƒÙ… Ù…Ø¨Ø§Ø±Ùƒ ØªÙ‚Ø¨Ù„ Ø§Ù„Ù„Ù‡ Ù…Ù†Ø§ ÙˆÙ…Ù†ÙƒÙ… ØµØ§Ù„Ø­ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ ÙŠØ§Ø±Ø¨</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10080</th>\n",
       "      <td>Ø´ÙˆÙ Ø³ØªÙˆØ±ÙŠ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10081 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  class\n",
       "0      Ø¨Ø§ÙŠÙ†Ø© ÙƒØªØ¨ØªÙˆÙ‡Ø§ Ù†Ù‡Ø§Ø± Ø§Ù„Ø³Ø¨Øª Ø­ØªÙ‰ Ø§Ù„ÙŠÙˆÙ… Ø¨Ø§Ø´ ØªØ¨Ø§Ø±ØªØ§Ø¬...    NaN\n",
       "1           Ù„ÙˆÙƒØ§Ù† Ø³ØªÙ†ÙŠØªÙˆ Ø­ØªÙ‰ Ù†Ù‡Ø§Ø± Ø§Ù„Ø®Ù…ÙŠØ³ Ø®ÙŠØ± Ùˆ Ø¯Ø±ØªÙˆ Ø¨ÙŠØ§Ù†    NaN\n",
       "2                         Ø§Ù„Ø²Ø¨ÙˆÙ† Ù„Ø§ Ø¯Ø®Ù„ Ù„Ù‡ ÙÙŠ Ø§Ù„Ø¨ÙƒØ§Ù„ÙˆØ±ÙŠØ§    NaN\n",
       "3      Ø´Ø±ÙƒØ©.... ØªØ¹Ø¬Ø² Ø¹Ù† ÙˆØ¶Ø¹ Ø£Ø¬Ù‡Ø²Ø© ØªØ´ÙˆÙŠØ´ Ø¨Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ø¥Ù…ØªØ­...    NaN\n",
       "4      Ø¯ÙˆÙ…Ø§Ø¬ Ø¹Ù†Ø¯ÙŠ Ù„Ø§ÙØ§Ù…ÙŠ ÙÙŠ Ø§Ù„ÙƒÙˆÙ†Øª Ù‡Ø°Ø§ ÙƒÙˆÙ† Ø¹Ø¨Ø±ØªÙ„ÙƒÙ… Ø¹Ù†...    NaN\n",
       "...                                                  ...    ...\n",
       "10076  Ø±Ø¬Ø¹ÙˆÙ„Ù†Ø§ Ø¹Ø±Ø¶ 1500Ù†ØªØ§Ø¹ 40Ø¬ÙŠØºØ§ Ø´Ù‡Ø±ÙŠÙ† Ù…Ø´ÙŠ Ø´Ù‡Ø± Ù‡ÙƒØ°Ø§...    0.0\n",
       "10077        Ø§Ù†Ø¸Ø±ÙˆØ§ Ø¥Ù„Ù‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙŠØ§ Ø¯Ø¬ÙŠØ²ÙŠ Ø¨ÙÙÙÙÙÙÙÙÙÙÙÙ    0.0\n",
       "10078  ØµØ­ Ø¹ÙŠØ¯Ùƒ Ø¬ÙŠØ²ÙŠ Ø´ÙˆÙŠ Ø§ØªÙ‡Ù„Ù‰ ÙƒÙˆÙ†ÙŠÙƒØ³ÙŠÙˆ Ø¸Ø¹ÙŠÙØ© ÙˆØ¹Ø±ÙˆØ¸ Ø´Ùˆ...    0.0\n",
       "10079  Ø¹ÙŠØ¯ÙƒÙ… Ù…Ø¨Ø§Ø±Ùƒ ØªÙ‚Ø¨Ù„ Ø§Ù„Ù„Ù‡ Ù…Ù†Ø§ ÙˆÙ…Ù†ÙƒÙ… ØµØ§Ù„Ø­ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ ÙŠØ§Ø±Ø¨    0.0\n",
       "10080                                          Ø´ÙˆÙ Ø³ØªÙˆØ±ÙŠ    0.0\n",
       "\n",
       "[10081 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆÙ†ÙŠÙƒØ³ÙŠÙˆØ§ Ø§Ù„Ø²ÙŠÙ†Ø© ØªØ§Ø¹ÙƒÙ… Ø§Ù„Ù„Ù‡ ÙŠØ°Ù„ÙƒÙ…</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÙØ¹Ù„ÙˆÙ„ÙŠ Ø¹Ø±Ø¶ Ø§Ù…ØªÙŠØ§Ø²</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bon cnx ta3 djezzy mtsla7ch gae l  pubg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø­Ø³Ø§Ù… Ø¨Ù† Ø¹Ø¨Ø±</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ØªÙ… Ù‚Ø·Ø¹ Ø§Ù„Ø§Ù†ØªØ±Ù†Øª Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ØŒ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10076</th>\n",
       "      <td>@sarra.hayat mabghach yetla3li</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10077</th>\n",
       "      <td>Hahaha</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>Ù…Ù†Ø§Ø´ Ø¹Ø§ÙŠØ´ÙŠÙ† ÙÙŠ Ø¨Ù„Ø§Ø¯ ÙˆØ§Ø­Ø¯Ø© !</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>Wallah ma tahchmou ya sraqin lmliha ki wlitou ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10080</th>\n",
       "      <td>Ø¬ÙŠØ²ÙŠ Ù‡Ø§Ø¯ÙŠ Ù…Ù‚ÙˆØ¯Ø§ Ù‚Ø§Ø¹ ÙÙŠ ÙƒÙ†ÙŠÙƒØ³ÙŠÙˆ</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10081 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  class\n",
       "0                Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆÙ†ÙŠÙƒØ³ÙŠÙˆØ§ Ø§Ù„Ø²ÙŠÙ†Ø© ØªØ§Ø¹ÙƒÙ… Ø§Ù„Ù„Ù‡ ÙŠØ°Ù„ÙƒÙ…   -1.0\n",
       "1                                      ÙØ¹Ù„ÙˆÙ„ÙŠ Ø¹Ø±Ø¶ Ø§Ù…ØªÙŠØ§Ø²    NaN\n",
       "2                Bon cnx ta3 djezzy mtsla7ch gae l  pubg    NaN\n",
       "3                                            Ø­Ø³Ø§Ù… Ø¨Ù† Ø¹Ø¨Ø±    NaN\n",
       "4                             ØªÙ… Ù‚Ø·Ø¹ Ø§Ù„Ø§Ù†ØªØ±Ù†Øª Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ØŒ    NaN\n",
       "...                                                  ...    ...\n",
       "10076                     @sarra.hayat mabghach yetla3li    0.0\n",
       "10077                                             Hahaha    0.0\n",
       "10078                        Ù…Ù†Ø§Ø´ Ø¹Ø§ÙŠØ´ÙŠÙ† ÙÙŠ Ø¨Ù„Ø§Ø¯ ÙˆØ§Ø­Ø¯Ø© !    NaN\n",
       "10079  Wallah ma tahchmou ya sraqin lmliha ki wlitou ...    NaN\n",
       "10080                     Ø¬ÙŠØ²ÙŠ Ù‡Ø§Ø¯ÙŠ Ù…Ù‚ÙˆØ¯Ø§ Ù‚Ø§Ø¹ ÙÙŠ ÙƒÙ†ÙŠÙƒØ³ÙŠÙˆ   -1.0\n",
       "\n",
       "[10081 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset = ['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "---\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family:Georgia'> Preprocessing of Text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> Function to Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_emoji(text):\n",
    "    return emoji.replace_emoji(text,replace=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loukan temdou alef jiga batel tqa3dou halazouuun .\n"
     ]
    }
   ],
   "source": [
    "# Load stopwords for each language\n",
    "with open('C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/Algerian-Arabic-stop-words.txt', 'r', encoding='utf-8') as f:\n",
    "    stop_words_ar_dz = set([line.strip() for line in f])\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "stop_words_fr = set(stopwords.words('french'))\n",
    "# Create a custom tokenizer for Arabic words\n",
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "# Define a function to remove stop words from a text\n",
    "def remove_stopwords(text):\n",
    "    words = tokenizer.tokenize(text)\n",
    "    words_filtered = []\n",
    "    for word in words:\n",
    "        if word not in stop_words_ar_dz and word not in stop_words_en and word not in stop_words_fr:\n",
    "            words_filtered.append(word)\n",
    "    return ' '.join(words_filtered)\n",
    "tet = \"Wlh loukan temdou alef jiga batel tqa3dou halazouuun.\"\n",
    "tet = remove_stopwords(tet)\n",
    "print(tet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> Fucntion to remove special characters, URLs, duplicated letters, punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Apply the clean_text function to the desired column(s) in the DataFrame\\nif df['comments'].dtype == 'object':\\n    df['comments_clean'] = df['comments'].apply(clean_text)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to perform the text cleaning operations\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation marks \n",
    "    text = re.sub(r'[@#&$]\\w+', '', text)  # Remove special characters\n",
    "    #text = re.sub(r'\\d+', '', text)  # Remove numbers \n",
    "    text = re.sub(r'(\\w)\\1+', r'\\1', text) # remove duplicated letters\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    return text\n",
    "\n",
    "'''# Apply the clean_text function to the desired column(s) in the DataFrame\n",
    "if df['comments'].dtype == 'object':\n",
    "    df['comments_clean'] = df['comments'].apply(clean_text)'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> Function to remove mutiple sequence spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mult_spaces(text):\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> Function to Preprocess the text by applying all above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = strip_emoji(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = clean_text(text)\n",
    "    text = remove_mult_spaces(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIGNETWORK\\AppData\\Local\\Temp\\ipykernel_4440\\2574735620.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['comments_clean'] = df['comments'].apply(preprocess)\n"
     ]
    }
   ],
   "source": [
    "if df['comments'].dtype == 'object':\n",
    "    df['comments_clean'] = df['comments'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>class</th>\n",
       "      <th>comments_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>Ù†ÙƒØªÙˆÙ‡Ø§ Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø­ÙƒÙ… Ù‡Ø°Ø§ ÙˆØ§Ø´ Ù†Ù‚ÙˆÙ„ÙƒÙ… .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ù†ÙƒØªÙˆÙ‡Ø§ Ø±ÙˆØ§Ø­ÙƒÙ… Ù†Ù‚ÙˆÙ„ÙƒÙ…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>Ø§Ù„Ø¨ÙƒØ§Ù„ÙˆØ±ÙŠØ§ Ø¨Ù‚Ø§ÙˆÙ„Ù‡Ø§ ÙŠÙˆÙ…ÙŠÙ† ÙˆØªØ®Ù„Øµ Ù…Ø§Ø²Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ Ø¹Ù„Ù‰...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø§Ù„Ø¨ÙƒØ§Ù„ÙˆØ±ÙŠØ§ Ø¨Ù‚Ø§ÙˆÙ„Ù‡Ø§ ÙŠÙˆÙ…ÙŠÙ† ÙˆØªØ®Ù„Øµ Ù…Ø§Ø²Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ Ø§Ù„Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6454</th>\n",
       "      <td>PHANTOM ND â¤ï¸ğŸ‡©ğŸ‡¿âœŒï¸ğŸ”¥ğŸ’ª</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHANTOM ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>Ø§Ø°Ø§ Ù…Ù…ÙƒÙ† Ù…Ø§Ù†Ù‚Ø¯Ø±Ø´ Ù†ÙÙ„ÙŠÙƒØ³ÙŠ Ù…Ù† Ø¹Ù†Ø¯ÙŠ Ù„Ø´Ø®Øµ Ø¢Ø®Ø± Ø¬Ø±Ø¨Øª...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ø§Ø°Ø§ Ù…ÙƒÙ† Ù…Ø§Ù†Ù‚Ø¯Ø±Ø´ Ù†ÙÙ„ÙŠÙƒØ³ÙŠ Ø¹Ù†Ø¯ÙŠ Ù„Ø´Ø®Øµ Ø¢Ø®Ø± Ø¬Ø±Ø¨Øª 70 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>ØªÙ… Ù†Ø´Ø± Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†Ø´ÙˆØ± ÙŠÙˆÙ… Ø§Ù„Ø³Ø¨Øª Ø¨Ø³Ø¨Ø¨ Ø«Ù‚Ù„ Ø§Ù„Ø§Ù†ØªØ±Ù†Øª...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ØªÙ… Ù†Ø´Ø± Ø§Ù„Ù…Ù†Ø´ÙˆØ± ÙŠÙˆÙ… Ø§Ù„Ø³Ø¨Øª Ø¨Ø³Ø¨ Ø«Ù‚Ù„ Ø§Ù„Ø§Ù†ØªØ±Ù†Øª Ø²ÙŠÙ†Ø©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8930</th>\n",
       "      <td>Pubg mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pubg mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>Ù‚Ø§Ù„ ÙÙŠÙ‡ ÙØ§ÙŠØ¯</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ÙØ§ÙŠØ¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7617</th>\n",
       "      <td>Ø­ØªÙ‰ Ù Ø§Ù„Ø§Ø¹ØªØ°Ø§Ø± Ù…ØªØ£Ø®Ø±ÙŠÙ† ÙƒØ§Ù„Ø¹Ø§Ø¯Ø©</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø§Ù„Ø§Ø¹ØªØ°Ø§Ø± Ù…ØªØ£Ø®Ø±ÙŠÙ† ÙƒØ§Ù„Ø¹Ø§Ø¯Ø©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ø¹Ù†Ø¯ÙŠ Ø¬ÙŠØ²ÙŠ ÙˆØ§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ØŒ Ù…Ø§Ø´ÙƒÙŠØªÙ„Ùƒ Ù…Ø§Ø´ÙƒÙŠØª Ù„ÙˆØ§Ø­Ø¯ Ø§ÙˆØ®Ø±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø¹Ù†Ø¯ÙŠ Ø¬ÙŠØ²ÙŠ ÙˆØ§Ù„Ø­Ù…Ø¯ Ù„Ù‡ Ù…Ø§Ø´ÙƒÙŠØªÙ„Ùƒ Ù…Ø§Ø´ÙƒÙŠØª Ù„ÙˆØ§Ø­Ø¯ Ø§ÙˆØ®Ø±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>Ø£Ù†Ù‡ Ø§Ù„Ù†ÙØ§Ù‚ ÙŠØ§ Ù‡Ù†Ø¯</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ø£Ù†Ù‡ Ø§Ù„Ù†ÙØ§Ù‚ Ù‡Ù†Ø¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Ø¬Ø§Ø²ÙŠ ÙŠØ³Ù„Ù… Ø¹Ù„ÙŠÙƒ Ø£Ø­Ù…Ø¯ Ù…Ø²Ø¨Ø´</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø¬Ø§Ø²ÙŠ ÙŠØ³Ù„Ù… Ø£Ø­Ù…Ø¯ Ù…Ø²Ø¨Ø´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>Mdrr allah yahdikom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mdr alah yahdikom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>EL Rey Ressan ÙˆØ§Ù„Ù„Ù‡ Ù…ÙƒØ§Ø´ Ø­ØªØ§ ØªØ¹ÙˆÙŠØ¶Ø§Øª</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EL Rey Resan ÙˆØ§Ù„Ù‡ Ø­ØªØ§ ØªØ¹ÙˆÙŠØ¶Ø§Øª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>Dirolna la3bt free fire illimitÃ© dok tchri dza...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dirolna la3bt fre fire ilimitÃ© tchri dzayr kml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>Stivane Stiv ØµØ­ Ø¹ÙŠØ¯ÙƒÙ… ğŸ™‚</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stivane Stiv ØµØ­ Ø¹ÙŠØ¯ÙƒÙ…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9638</th>\n",
       "      <td>Ù…Ø³Ø§Ø¨Ù‚Ø© Ø¨Ù†ÙƒÙ‡Ø© Ù†Ù‚ÙˆØ´Ø§ ğŸ™ŒğŸ˜ª</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ù…Ø³Ø§Ø¨Ù‚Ø© Ø¨Ù†ÙƒÙ‡Ø© Ù†Ù‚ÙˆØ´Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9826</th>\n",
       "      <td>Ø¹Ù†Ø¯ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø¹Ù†Ø¯ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>ÙˆØ§Ø§Ø§Ø´ Ø¯Ø®Ù„ÙƒÙ… ÙØ§Ù„Ø¨Ø§Ùƒ ØŸ Ù†ØªÙˆÙ…Ø§ Ø´Ø±ÙƒØ© Ø¥ØªØµØ§Ù„Ø§Øª ÙˆÙ„Ø§ ÙˆØ²...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ÙˆØ§Ø´ Ø¯Ø®Ù„ÙƒÙ… ÙØ§Ù„Ø¨Ø§Ùƒ Ù†ØªÙˆÙ…Ø§ Ø´Ø±ÙƒØ© Ø¥ØªØµØ§Ù„Ø§Øª ÙˆØ²Ø§Ø±Ø© ØªØ¹Ù„ÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>@med___mer Ø§Ùˆ ÙƒØªØ¨Ù„Ùƒ Ù…Ø¯Ù‰ Ø§Ù„Ø­ÙŠØ§Ø©</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ÙƒØªØ¨Ù„Ùƒ Ù…Ø¯Ù‰ Ø§Ù„Ø­ÙŠØ§Ø©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9600</th>\n",
       "      <td>Ù…Ø¶ÙŠØ¹ Ù„Ù„ÙˆÙ‚Øª</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ù…Ø¶ÙŠØ¹ Ù„ÙˆÙ‚Øª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>Ø­Ù„Ø²ÙˆÙ†ÙŠ ÙŠØ§Ø´ÙƒØ¨</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø­Ù„Ø²ÙˆÙ†ÙŠ ÙŠØ§Ø´ÙƒØ¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Tog3od avie wla kifh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tog3od avie wla kifh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Ø«Ù‚ÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙ„Ø© ğŸ™„ğŸ™„ğŸ™„ğŸ™„</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø«Ù‚ÙŠÙ„Ø©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Ø¯Ø¬ÙŠØ²ÙŠ Ù…Ø§ ØªØµÙ„Ø­Ø´ Ø¨ØºØ±Ø§Ù…... Ø¹Ù†Ø¯Ù‡Ø§ Ø§Ù„Ø¨ÙŠÙ†Ú¨ ÙˆÙ‡Ù…ÙŠ ÙˆÙƒØ°Ø¨...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø¯Ø¬ÙŠØ²ÙŠ ØªØµÙ„Ø­Ø´ Ø¨ØºØ±Ø§Ù… Ø¹Ù†Ø¯Ù‡Ø§ Ø§Ù„Ø¨ÙŠÙ†Ú¨ ÙˆÙ‡Ù…ÙŠ ÙˆÙƒØ°Ø¨ ÙƒØ°Ø¨ Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>Ø§Ø³Ù…Ø¹ ÙˆØ§Ø´ Ø±Ø§Ù‡Ù… ÙŠÙ‚ÙˆÙ„Ùˆ Ø±Ø§Ù‡Ù… ÙŠØ®Ù…Ù…Ùˆ ÙÙŠÙƒ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø§Ø³Ù…Ø¹ Ø±Ø§Ù‡Ù… ÙŠÙ‚ÙˆÙ„Ùˆ Ø±Ø§Ù‡Ù… ÙŠØ®Ù…Ùˆ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comments  class  \\\n",
       "5402                 Ù†ÙƒØªÙˆÙ‡Ø§ Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø­ÙƒÙ… Ù‡Ø°Ø§ ÙˆØ§Ø´ Ù†Ù‚ÙˆÙ„ÙƒÙ… .    NaN   \n",
       "2675  Ø§Ù„Ø¨ÙƒØ§Ù„ÙˆØ±ÙŠØ§ Ø¨Ù‚Ø§ÙˆÙ„Ù‡Ø§ ÙŠÙˆÙ…ÙŠÙ† ÙˆØªØ®Ù„Øµ Ù…Ø§Ø²Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ Ø¹Ù„Ù‰...    NaN   \n",
       "6454                                PHANTOM ND â¤ï¸ğŸ‡©ğŸ‡¿âœŒï¸ğŸ”¥ğŸ’ª    NaN   \n",
       "4573  Ø§Ø°Ø§ Ù…Ù…ÙƒÙ† Ù…Ø§Ù†Ù‚Ø¯Ø±Ø´ Ù†ÙÙ„ÙŠÙƒØ³ÙŠ Ù…Ù† Ø¹Ù†Ø¯ÙŠ Ù„Ø´Ø®Øµ Ø¢Ø®Ø± Ø¬Ø±Ø¨Øª...    0.0   \n",
       "8419  ØªÙ… Ù†Ø´Ø± Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†Ø´ÙˆØ± ÙŠÙˆÙ… Ø§Ù„Ø³Ø¨Øª Ø¨Ø³Ø¨Ø¨ Ø«Ù‚Ù„ Ø§Ù„Ø§Ù†ØªØ±Ù†Øª...    NaN   \n",
       "8930                                        Pubg mobile    NaN   \n",
       "9868                                       Ù‚Ø§Ù„ ÙÙŠÙ‡ ÙØ§ÙŠØ¯    NaN   \n",
       "7617                     Ø­ØªÙ‰ Ù Ø§Ù„Ø§Ø¹ØªØ°Ø§Ø± Ù…ØªØ£Ø®Ø±ÙŠÙ† ÙƒØ§Ù„Ø¹Ø§Ø¯Ø©    NaN   \n",
       "47     Ø¹Ù†Ø¯ÙŠ Ø¬ÙŠØ²ÙŠ ÙˆØ§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ØŒ Ù…Ø§Ø´ÙƒÙŠØªÙ„Ùƒ Ù…Ø§Ø´ÙƒÙŠØª Ù„ÙˆØ§Ø­Ø¯ Ø§ÙˆØ®Ø±    NaN   \n",
       "3252                                  Ø£Ù†Ù‡ Ø§Ù„Ù†ÙØ§Ù‚ ÙŠØ§ Ù‡Ù†Ø¯    1.0   \n",
       "192                            Ø¬Ø§Ø²ÙŠ ÙŠØ³Ù„Ù… Ø¹Ù„ÙŠÙƒ Ø£Ø­Ù…Ø¯ Ù…Ø²Ø¨Ø´    NaN   \n",
       "7829                                Mdrr allah yahdikom    NaN   \n",
       "8623               EL Rey Ressan ÙˆØ§Ù„Ù„Ù‡ Ù…ÙƒØ§Ø´ Ø­ØªØ§ ØªØ¹ÙˆÙŠØ¶Ø§Øª    0.0   \n",
       "4815  Dirolna la3bt free fire illimitÃ© dok tchri dza...    0.0   \n",
       "3826                            Stivane Stiv ØµØ­ Ø¹ÙŠØ¯ÙƒÙ… ğŸ™‚    0.0   \n",
       "9638                              Ù…Ø³Ø§Ø¨Ù‚Ø© Ø¨Ù†ÙƒÙ‡Ø© Ù†Ù‚ÙˆØ´Ø§ ğŸ™ŒğŸ˜ª    NaN   \n",
       "9826                                       Ø¹Ù†Ø¯ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±    NaN   \n",
       "8967  ÙˆØ§Ø§Ø§Ø´ Ø¯Ø®Ù„ÙƒÙ… ÙØ§Ù„Ø¨Ø§Ùƒ ØŸ Ù†ØªÙˆÙ…Ø§ Ø´Ø±ÙƒØ© Ø¥ØªØµØ§Ù„Ø§Øª ÙˆÙ„Ø§ ÙˆØ²...    NaN   \n",
       "3082                     @med___mer Ø§Ùˆ ÙƒØªØ¨Ù„Ùƒ Ù…Ø¯Ù‰ Ø§Ù„Ø­ÙŠØ§Ø©    0.0   \n",
       "9600                                         Ù…Ø¶ÙŠØ¹ Ù„Ù„ÙˆÙ‚Øª    NaN   \n",
       "6438                                       Ø­Ù„Ø²ÙˆÙ†ÙŠ ÙŠØ§Ø´ÙƒØ¨    NaN   \n",
       "359                                Tog3od avie wla kifh    0.0   \n",
       "682                                  Ø«Ù‚ÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙ„Ø© ğŸ™„ğŸ™„ğŸ™„ğŸ™„    NaN   \n",
       "590   Ø¯Ø¬ÙŠØ²ÙŠ Ù…Ø§ ØªØµÙ„Ø­Ø´ Ø¨ØºØ±Ø§Ù…... Ø¹Ù†Ø¯Ù‡Ø§ Ø§Ù„Ø¨ÙŠÙ†Ú¨ ÙˆÙ‡Ù…ÙŠ ÙˆÙƒØ°Ø¨...    NaN   \n",
       "2738                 Ø§Ø³Ù…Ø¹ ÙˆØ§Ø´ Ø±Ø§Ù‡Ù… ÙŠÙ‚ÙˆÙ„Ùˆ Ø±Ø§Ù‡Ù… ÙŠØ®Ù…Ù…Ùˆ ÙÙŠÙƒ    NaN   \n",
       "\n",
       "                                         comments_clean  \n",
       "5402                              Ù†ÙƒØªÙˆÙ‡Ø§ Ø±ÙˆØ§Ø­ÙƒÙ… Ù†Ù‚ÙˆÙ„ÙƒÙ…   \n",
       "2675  Ø§Ù„Ø¨ÙƒØ§Ù„ÙˆØ±ÙŠØ§ Ø¨Ù‚Ø§ÙˆÙ„Ù‡Ø§ ÙŠÙˆÙ…ÙŠÙ† ÙˆØªØ®Ù„Øµ Ù…Ø§Ø²Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ Ø§Ù„Ø§...  \n",
       "6454                                         PHANTOM ND  \n",
       "4573  Ø§Ø°Ø§ Ù…ÙƒÙ† Ù…Ø§Ù†Ù‚Ø¯Ø±Ø´ Ù†ÙÙ„ÙŠÙƒØ³ÙŠ Ø¹Ù†Ø¯ÙŠ Ù„Ø´Ø®Øµ Ø¢Ø®Ø± Ø¬Ø±Ø¨Øª 70 ...  \n",
       "8419  ØªÙ… Ù†Ø´Ø± Ø§Ù„Ù…Ù†Ø´ÙˆØ± ÙŠÙˆÙ… Ø§Ù„Ø³Ø¨Øª Ø¨Ø³Ø¨ Ø«Ù‚Ù„ Ø§Ù„Ø§Ù†ØªØ±Ù†Øª Ø²ÙŠÙ†Ø©...  \n",
       "8930                                        Pubg mobile  \n",
       "9868                                               ÙØ§ÙŠØ¯  \n",
       "7617                           Ø§Ù„Ø§Ø¹ØªØ°Ø§Ø± Ù…ØªØ£Ø®Ø±ÙŠÙ† ÙƒØ§Ù„Ø¹Ø§Ø¯Ø©  \n",
       "47       Ø¹Ù†Ø¯ÙŠ Ø¬ÙŠØ²ÙŠ ÙˆØ§Ù„Ø­Ù…Ø¯ Ù„Ù‡ Ù…Ø§Ø´ÙƒÙŠØªÙ„Ùƒ Ù…Ø§Ø´ÙƒÙŠØª Ù„ÙˆØ§Ø­Ø¯ Ø§ÙˆØ®Ø±  \n",
       "3252                                     Ø£Ù†Ù‡ Ø§Ù„Ù†ÙØ§Ù‚ Ù‡Ù†Ø¯  \n",
       "192                                 Ø¬Ø§Ø²ÙŠ ÙŠØ³Ù„Ù… Ø£Ø­Ù…Ø¯ Ù…Ø²Ø¨Ø´  \n",
       "7829                                  Mdr alah yahdikom  \n",
       "8623                      EL Rey Resan ÙˆØ§Ù„Ù‡ Ø­ØªØ§ ØªØ¹ÙˆÙŠØ¶Ø§Øª  \n",
       "4815  Dirolna la3bt fre fire ilimitÃ© tchri dzayr kml...  \n",
       "3826                              Stivane Stiv ØµØ­ Ø¹ÙŠØ¯ÙƒÙ…  \n",
       "9638                                 Ù…Ø³Ø§Ø¨Ù‚Ø© Ø¨Ù†ÙƒÙ‡Ø© Ù†Ù‚ÙˆØ´Ø§  \n",
       "9826                                       Ø¹Ù†Ø¯ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±  \n",
       "8967  ÙˆØ§Ø´ Ø¯Ø®Ù„ÙƒÙ… ÙØ§Ù„Ø¨Ø§Ùƒ Ù†ØªÙˆÙ…Ø§ Ø´Ø±ÙƒØ© Ø¥ØªØµØ§Ù„Ø§Øª ÙˆØ²Ø§Ø±Ø© ØªØ¹Ù„ÙŠ...  \n",
       "3082                                   ÙƒØªØ¨Ù„Ùƒ Ù…Ø¯Ù‰ Ø§Ù„Ø­ÙŠØ§Ø©  \n",
       "9600                                          Ù…Ø¶ÙŠØ¹ Ù„ÙˆÙ‚Øª  \n",
       "6438                                       Ø­Ù„Ø²ÙˆÙ†ÙŠ ÙŠØ§Ø´ÙƒØ¨  \n",
       "359                                Tog3od avie wla kifh  \n",
       "682                                               Ø«Ù‚ÙŠÙ„Ø©  \n",
       "590   Ø¯Ø¬ÙŠØ²ÙŠ ØªØµÙ„Ø­Ø´ Ø¨ØºØ±Ø§Ù… Ø¹Ù†Ø¯Ù‡Ø§ Ø§Ù„Ø¨ÙŠÙ†Ú¨ ÙˆÙ‡Ù…ÙŠ ÙˆÙƒØ°Ø¨ ÙƒØ°Ø¨ Ø§...  \n",
       "2738                          Ø§Ø³Ù…Ø¹ Ø±Ø§Ù‡Ù… ÙŠÙ‚ÙˆÙ„Ùˆ Ø±Ø§Ù‡Ù… ÙŠØ®Ù…Ùˆ  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments_clean'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIGNETWORK\\AppData\\Local\\Temp\\ipykernel_4440\\3493959318.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['comments_clean'].replace('', np.nan, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments_clean'].replace('', np.nan, inplace=True)\n",
    "missing_values = df[df['comments_clean'].isnull()]\n",
    "#df=df.dropna(subset = ['comments_clean'])\n",
    "len(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset = ['comments_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop_duplicates(subset=[\"comments_clean\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_det(texte):\n",
    "    langage = detect(texte)\n",
    "    if langage not in ['en','fr']:\n",
    "        langage = 'dz'\n",
    "    \n",
    "    return langage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary\n",
    "mapping = {\n",
    "    'a': 'Ø§', 'kh':'Ø®','sh':'Ø´','ch':'Ø´','b': 'Ø¨', 'c': 'Ø³', 'd': 'Ø¯', 'e': 'ÙŠ', 'f': 'Ù',\n",
    "    'g': 'Ú¨', 'h': 'Ù‡', 'i': 'ÙŠ', 'j': 'Ø¬', 'k': 'Ùƒ', 'l': 'Ù„',\n",
    "    'm': 'Ù…', 'n': 'Ù†', 'o': 'Ùˆ', 'p': 'Ø¨', 'q': 'Ù‚', 'r': 'Ø±',\n",
    "    's': 'Øµ', 't': 'Øª', 'u': 'Ùˆ', 'v': 'Ú¥', 'w': 'Ùˆ', 'x': 'ÙƒØ³',\n",
    "    'y': 'ÙŠ', 'z': 'Ø²','9':'Ù‚','7':'Ø­'\n",
    "}\n",
    "# Define the translation function\n",
    "def arabizi_to_arabic(text):\n",
    "    # Replace each Arabizi letter with its corresponding Arabic alphabet dialect letter\n",
    "    for letter, value in mapping.items():\n",
    "        text = re.sub(letter, value, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DØ¬ÙŠØ²Ø²ÙŠ Ù…Ø¹Ù†Ø¯ÙŠØ´ Ø§Ù„Ù…Ø§Ù„ Ø¨Ø§Ø´ Ù†ÙÙ„ÙŠÙƒØ³ÙŠ Ø§Ø¨Ø¹ØªÙ„ÙŠ100Ø¯Ø¬\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "arabizi_text = \"Djezzy Ù…Ø¹Ù†Ø¯ÙŠØ´ Ø§Ù„Ù…Ø§Ù„ Ø¨Ø§Ø´ Ù†ÙÙ„ÙŠÙƒØ³ÙŠ Ø§Ø¨Ø¹ØªÙ„ÙŠ100Ø¯Ø¬\"\n",
    "arabic_text = arabizi_to_arabic(arabizi_text)\n",
    "print(arabic_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFXLMRobertaForSequenceClassification were initialized from the model checkpoint at papluca/xlm-roberta-base-language-detection.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr\n"
     ]
    }
   ],
   "source": [
    "# Load the language detection pipeline\n",
    "lang_detect = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "# Text to classify\n",
    "text = \"Pourquoi vous limitez le dÃ©bit ?.\"\n",
    "\n",
    "# Run the language detection pipeline\n",
    "result = lang_detect(text)\n",
    "\n",
    "# Print the detected language\n",
    "print(result[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt\n"
     ]
    }
   ],
   "source": [
    "# Text to classify\n",
    "text = \"Vive mobilis\"\n",
    "\n",
    "# Run the language detection pipeline\n",
    "result = lang_detect(text)\n",
    "\n",
    "# Print the detected language\n",
    "print(result[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "# Utilisation de la mÃ©thode SequenceMatcher pour calculer la similaritÃ© entre deux chaÃ®nes de caractÃ¨res\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "def detecter_langage(texte):\n",
    "    # DÃ©tection de la langue avec langdetect\n",
    "    langage = detect(texte)\n",
    "    \n",
    "   #  Si le texte est similaire Ã  l'anglais, au franÃ§ais ou Ã  l'arabe, il est classÃ© comme dialecte algÃ©rien\n",
    "    if langage in ['en', 'fr', 'ar']:\n",
    "        similarites = {\n",
    "            'en': similar(texte, 'english'),\n",
    "            'fr': similar(texte, 'franÃ§ais'),\n",
    "            'ar': similar(texte, 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©')\n",
    "        }\n",
    "        # Le texte est classÃ© comme dialecte algÃ©rien s'il est plus similaire Ã  une de ces langues qu'Ã  l'autre\n",
    "        if max(similarites.values()) == similarites[langage] or langage =='so':\n",
    "            langage = 'dz'\n",
    "    \n",
    "    return langage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Kanet 3endi beseh rÃ©seau fiha mekhsous bezaf f la willaya de Tizi ouzou apart le centre ville makanch rÃ©seau\"\n",
    "print(detecter_langage(txt))\n",
    "  #  df['len'] = df['comments_nett'].apply(detecter_langage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIGNETWORK\\AppData\\Local\\Temp\\ipykernel_19160\\2026574333.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.at[index, 'language'] = result[0]['label']\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text = str(row['comments_clean'])\n",
    "    if text:\n",
    "        try:\n",
    "            result = lang_detect(text)\n",
    "            df.at[index, 'language'] = result[0]['label']\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64a6b5e2244e422069341277cd1317ebf2b03c7f83a07567628f5bb1b1823540"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
