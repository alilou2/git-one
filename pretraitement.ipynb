{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BIGNETWORK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\BIGNETWORK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import emoji\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alg_telcom_2_2k.xlsx',\n",
       " 'facebook (1).xlsx',\n",
       " 'facebook (2).xlsx',\n",
       " 'instagram (1).xlsx',\n",
       " 'instagram (2).xlsx',\n",
       " 'instagram (3).xlsx',\n",
       " 'instagram (4).xlsx',\n",
       " 'instagram (5).xlsx',\n",
       " 'instagram (6).xlsx',\n",
       " 'instagram (7).xlsx',\n",
       " 'instagram (8).xlsx',\n",
       " 'instagram.xlsx']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = ('C:/Users/BIGNETWORK/Desktop/PFE/dataset/resaux scraper')\n",
    "files = os.listdir(path)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alg_telcom_2_2k.xlsx',\n",
       " 'facebook (1).xlsx',\n",
       " 'facebook (2).xlsx',\n",
       " 'instagram (1).xlsx',\n",
       " 'instagram (2).xlsx',\n",
       " 'instagram (3).xlsx',\n",
       " 'instagram (4).xlsx',\n",
       " 'instagram (5).xlsx',\n",
       " 'instagram (6).xlsx',\n",
       " 'instagram (7).xlsx',\n",
       " 'instagram (8).xlsx',\n",
       " 'instagram.xlsx']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_xls = [f for f in files if f[-4:] == 'xlsx']\n",
    "files_xls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for f in files_xls:\n",
    "    data = pd.read_excel(f'C:/Users/BIGNETWORK/Desktop/PFE/dataset/resaux scraper/{f}')\n",
    "    data.drop(data.index[0:0],inplace=True)\n",
    "    df = df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comments  class\n",
      "0    Ø¨Ø§ÙŠÙ†Ø© ÙƒØªØ¨ØªÙˆÙ‡Ø§ Ù†Ù‡Ø§Ø± Ø§Ù„Ø³Ø¨Øª Ø­ØªÙ‰ Ø§Ù„ÙŠÙˆÙ… Ø¨Ø§Ø´ ØªØ¨Ø§Ø±ØªØ§Ø¬...    NaN\n",
      "1         Ù„ÙˆÙƒØ§Ù† Ø³ØªÙ†ÙŠØªÙˆ Ø­ØªÙ‰ Ù†Ù‡Ø§Ø± Ø§Ù„Ø®Ù…ÙŠØ³ Ø®ÙŠØ± Ùˆ Ø¯Ø±ØªÙˆ Ø¨ÙŠØ§Ù†    NaN\n",
      "2                       Ø§Ù„Ø²Ø¨ÙˆÙ† Ù„Ø§ Ø¯Ø®Ù„ Ù„Ù‡ ÙÙŠ Ø§Ù„Ø¨ÙƒØ§Ù„ÙˆØ±ÙŠØ§    NaN\n",
      "3    Ø´Ø±ÙƒØ©.... ØªØ¹Ø¬Ø² Ø¹Ù† ÙˆØ¶Ø¹ Ø£Ø¬Ù‡Ø²Ø© ØªØ´ÙˆÙŠØ´ Ø¨Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ø¥Ù…ØªØ­...    NaN\n",
      "4    Ø¯ÙˆÙ…Ø§Ø¬ Ø¹Ù†Ø¯ÙŠ Ù„Ø§ÙØ§Ù…ÙŠ ÙÙŠ Ø§Ù„ÙƒÙˆÙ†Øª Ù‡Ø°Ø§ ÙƒÙˆÙ† Ø¹Ø¨Ø±ØªÙ„ÙƒÙ… Ø¹Ù†...    NaN\n",
      "..                                                 ...    ...\n",
      "785                                                  ğŸ”¥    NaN\n",
      "786                                               â¤ï¸â¤ï¸    NaN\n",
      "787                                               â¤ï¸â¤ï¸    NaN\n",
      "788                         NChllh  b rebi ping yhbt ğŸ˜‚    NaN\n",
      "789                                              â¤ï¸â¤ï¸ğŸ˜    NaN\n",
      "\n",
      "[6834 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"resaux_comments.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/resaux_comments.xlsx\")\n",
    "df1=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/hateonly_mehdi.xlsx\")\n",
    "df2=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/fb_comments.xlsx\")\n",
    "df3=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/hainer_ranim.xlsx\")\n",
    "df4=pd.read_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/datasets/neutre_mehdi.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df0, df1, df2, df3,df4], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>class</th>\n",
       "      <th>comments_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tagdo3o cnx men lhad hta lkhmis wzid jam3a mkn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tagdo3o cnx men lhad hta lkhmis wzid jam3a mkn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ùˆ ÙƒÙˆÙ†ÙŠÙƒØ³ÙŠÙˆÙ† Ø¯ÙŠØ§Ù„Ù‡Ø§ Ø±Ù‡Ø¬ Ùˆ Ø²ÙŠØ±Ùˆ ÙƒØ§Ø±ØªØ© Ùˆ Ù‡Ø¯Ø§ ÙˆÙŠÙ† ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ÙƒÙˆÙ†ÙŠÙƒØ³ÙŠÙˆÙ† Ø¯ÙŠØ§Ù„Ù‡Ø§ Ø±Ù‡Ø¬ Ø²ÙŠØ±Ùˆ ÙƒØ§Ø±ØªØ© Ù‡Ø¯Ø§ Ø¹Ø±ÙØª 60 gb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sera9in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sera9in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù‡Ø°ÙŠ Ø§Ù„ÙƒÙØ§Ø± Ø§Ùˆ Ù…Ø§Ø¯Ø§Ø±ÙˆÙ‡Ø§Ø´</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø§Ù„ÙƒÙØ§Ø± Ù…Ø§Ø¯Ø§Ø±ÙˆÙ‡Ø§Ø´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ØªØ§ÙÙ‡ÙŠÙ†   ÙˆØ®Ø¯Ù…Ø§ØªÙƒÙ… Ø¯ÙˆÙ† Ø§Ù„Ù…Ø³ØªÙˆÙ‰  ÙˆÙ…Ø§Ø´ÙƒÙŠØªØ´ ØªØªØ­Ø³Ù†Ùˆ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ØªØ§ÙÙ‡ÙŠÙ† ÙˆØ®Ø¯Ù…Ø§ØªÙƒÙ… Ø§Ù„Ù…Ø³ØªÙˆÙ‰ ÙˆÙ…Ø§Ø´ÙƒÙŠØªØ´ ØªØ­Ø³Ù†Ùˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10076</th>\n",
       "      <td>ØªØ­ÙŠØ§ Ø¬ÙŠØ²ÙŠ Ø±Ø§Ù‡ÙŠ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø´Ø¨ÙƒØ© 100/100 Ù…ØªØ³Ø±Ù‚Ø´ Ù†ÙƒÙ…...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ØªØ­ÙŠØ§ Ø¬ÙŠØ²ÙŠ Ø±Ø§Ù‡ÙŠ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø´Ø¨ÙƒØ© 10 10 Ù…ØªØ³Ø±Ù‚Ø´ Ù†ÙƒÙ…Ù„ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10077</th>\n",
       "      <td>Ø§Ù†Ø§ Ù…ÙƒØ§Ù† Ù…Ø§Ø¯Ø®Ù„Ù†ÙŠ ÙØ§Ù„Ø¨Ø§Ùƒ Ø±Ø§Ù†ÙŠ Ù†Ø®Ù„Øµ ÙÙŠÙ‡Ø§  ÙˆÙ‡Ø°Ø§ Ø­Ù‚ÙŠ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ù…Ø§Ø¯Ø®Ù„Ù†ÙŠ ÙØ§Ù„Ø¨Ø§Ùƒ Ø±Ø§Ù†ÙŠ Ù†Ø®Ù„Øµ ÙˆÙ‡Ø°Ø§ Ø­Ù‚ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>iOS !!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ§Ù„ÙƒÙˆÙ†ÙƒØ³ÙŠÙ† ØªØ§Ø¹ÙƒÙ… Ø±Ø¬Ø¹Øª ØªØ¹ÙŠÙ ØªØ¹ÙŠÙ ØªØ¹ÙŠÙŠÙŠÙŠÙ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ø§Ù„Ù‡ ÙŠØ§Ù„ÙƒÙˆÙ†ÙƒØ³ÙŠÙ† ØªØ§Ø¹ÙƒÙ… Ø±Ø¬Ø¹Øª ØªØ¹ÙŠÙ ØªØ¹ÙŠÙ ØªØ¹ÙŠÙ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10080</th>\n",
       "      <td>ÙƒÙ„ Ø´ÙŠØ¡ Ø«Ù‚ÙŠÙ„ Ø¹Ù†Ø¯ÙƒÙ… Ø­ØªÙ‰ Ø§Ù„Ø§Ø´Ø¹Ø§Ø±Ø§Øª</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø´ÙŠØ¡ Ø«Ù‚ÙŠÙ„ Ø§Ù„Ø§Ø´Ø¹Ø§Ø±Ø§Øª</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9840 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  class  \\\n",
       "0      Tagdo3o cnx men lhad hta lkhmis wzid jam3a mkn...    NaN   \n",
       "1      Ùˆ ÙƒÙˆÙ†ÙŠÙƒØ³ÙŠÙˆÙ† Ø¯ÙŠØ§Ù„Ù‡Ø§ Ø±Ù‡Ø¬ Ùˆ Ø²ÙŠØ±Ùˆ ÙƒØ§Ø±ØªØ© Ùˆ Ù‡Ø¯Ø§ ÙˆÙŠÙ† ...    NaN   \n",
       "2                                                Sera9in    NaN   \n",
       "3                                Ù‡Ø°ÙŠ Ø§Ù„ÙƒÙØ§Ø± Ø§Ùˆ Ù…Ø§Ø¯Ø§Ø±ÙˆÙ‡Ø§Ø´    NaN   \n",
       "4         ØªØ§ÙÙ‡ÙŠÙ†   ÙˆØ®Ø¯Ù…Ø§ØªÙƒÙ… Ø¯ÙˆÙ† Ø§Ù„Ù…Ø³ØªÙˆÙ‰  ÙˆÙ…Ø§Ø´ÙƒÙŠØªØ´ ØªØªØ­Ø³Ù†Ùˆ    NaN   \n",
       "...                                                  ...    ...   \n",
       "10076  ØªØ­ÙŠØ§ Ø¬ÙŠØ²ÙŠ Ø±Ø§Ù‡ÙŠ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø´Ø¨ÙƒØ© 100/100 Ù…ØªØ³Ø±Ù‚Ø´ Ù†ÙƒÙ…...    NaN   \n",
       "10077   Ø§Ù†Ø§ Ù…ÙƒØ§Ù† Ù…Ø§Ø¯Ø®Ù„Ù†ÙŠ ÙØ§Ù„Ø¨Ø§Ùƒ Ø±Ø§Ù†ÙŠ Ù†Ø®Ù„Øµ ÙÙŠÙ‡Ø§  ÙˆÙ‡Ø°Ø§ Ø­Ù‚ÙŠ    NaN   \n",
       "10078                                            iOS !!!    NaN   \n",
       "10079       Ø§Ù„Ù„Ù‡ ÙŠØ§Ù„ÙƒÙˆÙ†ÙƒØ³ÙŠÙ† ØªØ§Ø¹ÙƒÙ… Ø±Ø¬Ø¹Øª ØªØ¹ÙŠÙ ØªØ¹ÙŠÙ ØªØ¹ÙŠÙŠÙŠÙŠÙ    1.0   \n",
       "10080                    ÙƒÙ„ Ø´ÙŠØ¡ Ø«Ù‚ÙŠÙ„ Ø¹Ù†Ø¯ÙƒÙ… Ø­ØªÙ‰ Ø§Ù„Ø§Ø´Ø¹Ø§Ø±Ø§Øª    NaN   \n",
       "\n",
       "                                          comments_clean  \n",
       "0      Tagdo3o cnx men lhad hta lkhmis wzid jam3a mkn...  \n",
       "1      ÙƒÙˆÙ†ÙŠÙƒØ³ÙŠÙˆÙ† Ø¯ÙŠØ§Ù„Ù‡Ø§ Ø±Ù‡Ø¬ Ø²ÙŠØ±Ùˆ ÙƒØ§Ø±ØªØ© Ù‡Ø¯Ø§ Ø¹Ø±ÙØª 60 gb...  \n",
       "2                                                Sera9in  \n",
       "3                                       Ø§Ù„ÙƒÙØ§Ø± Ù…Ø§Ø¯Ø§Ø±ÙˆÙ‡Ø§Ø´  \n",
       "4                 ØªØ§ÙÙ‡ÙŠÙ† ÙˆØ®Ø¯Ù…Ø§ØªÙƒÙ… Ø§Ù„Ù…Ø³ØªÙˆÙ‰ ÙˆÙ…Ø§Ø´ÙƒÙŠØªØ´ ØªØ­Ø³Ù†Ùˆ  \n",
       "...                                                  ...  \n",
       "10076  ØªØ­ÙŠØ§ Ø¬ÙŠØ²ÙŠ Ø±Ø§Ù‡ÙŠ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø´Ø¨ÙƒØ© 10 10 Ù…ØªØ³Ø±Ù‚Ø´ Ù†ÙƒÙ…Ù„ ...  \n",
       "10077                  Ù…Ø§Ø¯Ø®Ù„Ù†ÙŠ ÙØ§Ù„Ø¨Ø§Ùƒ Ø±Ø§Ù†ÙŠ Ù†Ø®Ù„Øµ ÙˆÙ‡Ø°Ø§ Ø­Ù‚ÙŠ  \n",
       "10078                                               iOS   \n",
       "10079           Ø§Ù„Ù‡ ÙŠØ§Ù„ÙƒÙˆÙ†ÙƒØ³ÙŠÙ† ØªØ§Ø¹ÙƒÙ… Ø±Ø¬Ø¹Øª ØªØ¹ÙŠÙ ØªØ¹ÙŠÙ ØªØ¹ÙŠÙ  \n",
       "10080                                 Ø´ÙŠØ¡ Ø«Ù‚ÙŠÙ„ Ø§Ù„Ø§Ø´Ø¹Ø§Ø±Ø§Øª  \n",
       "\n",
       "[9840 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"C:/Users/BIGNETWORK/Desktop/PFE/dataset/dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset = ['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "---\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family:Georgia'> Preprocessing of Text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> Function to Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_emoji(text):\n",
    "    return emoji.replace_emoji(text,replace=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loukan temdou alef jiga batel tqa3dou halazouuun .\n"
     ]
    }
   ],
   "source": [
    "# Load stopwords for each language\n",
    "with open('C:/Users/BIGNETWORK/Desktop/PFE/dataset/project/git-one/Algerian-Arabic-stop-words.txt', 'r', encoding='utf-8') as f:\n",
    "    stop_words_ar_dz = set([line.strip() for line in f])\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "stop_words_fr = set(stopwords.words('french'))\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# Create a custom tokenizer for Arabic words\n",
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "# Define a function to remove stop words from a text\n",
    "def remove_stopwords(text):\n",
    "    words = tokenizer.tokenize(text)\n",
    "    words_filtered = []\n",
    "    for word in words:\n",
    "        if word not in stop_words_ar_dz and word not in stop_words_en and word not in stop_words_fr:\n",
    "            words_filtered.append(word)\n",
    "    return ' '.join(words_filtered)\n",
    "tet = \"Wlh loukan temdou alef jiga batel tqa3dou halazouuun.\"\n",
    "tet = remove_stopwords(tet)\n",
    "print(tet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> Fucntion to remove special characters, URLs, duplicated letters, punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Apply the clean_text function to the desired column(s) in the DataFrame\\nif df['comments'].dtype == 'object':\\n    df['comments_clean'] = df['comments'].apply(clean_text)\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to perform the text cleaning operations\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation marks \n",
    "    text = re.sub(r'[@#&$]\\w+', '', text)  # Remove special characters\n",
    "    #text = re.sub(r'\\d+', '', text)  # Remove numbers \n",
    "    text = re.sub(r'(\\w)\\1+', r'\\1', text) # remove duplicated letters\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    return text\n",
    "\n",
    "'''# Apply the clean_text function to the desired column(s) in the DataFrame\n",
    "if df['comments'].dtype == 'object':\n",
    "    df['comments_clean'] = df['comments'].apply(clean_text)'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> Function to remove mutiple sequence spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mult_spaces(text):\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:serif'> Function to Preprocess the text by applying all above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = strip_emoji(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = clean_text(text)\n",
    "    text = remove_mult_spaces(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIGNETWORK\\AppData\\Local\\Temp\\ipykernel_13008\\2574735620.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['comments_clean'] = df['comments'].apply(preprocess)\n"
     ]
    }
   ],
   "source": [
    "if df['comments'].dtype == 'object':\n",
    "    df['comments_clean'] = df['comments'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>class</th>\n",
       "      <th>comments_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>Ø³ÙƒØª Ø¯Ù‡Ø±Ø§Ù‹ .. ÙˆÙ†Ø·Ù‚ ÙƒÙØ±Ø§Ù‹</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø³ÙƒØª Ø¯Ù‡Ø±Ø§ ÙˆÙ†Ø·Ù‚ ÙƒÙØ±Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Ø³Ø±Ø§Ù‚ ÙŠÙÙ„ÙŠÙƒØ³ÙŠ Ù„ÙˆØ§Ø­Ø¯ ÙŠØ¬ÙŠ ÙŠØ§ÙƒØªÙŠÙÙŠ ÙŠÙ„Ù‚Ø§Ù‡Ø§ Ø±Ø§Ø­Øª Ø¯Ø±Ø§...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø³Ø±Ø§Ù‚ ÙŠÙÙ„ÙŠÙƒØ³ÙŠ Ù„ÙˆØ§Ø­Ø¯ ÙŠØ¬ÙŠ ÙŠØ§ÙƒØªÙŠÙÙŠ ÙŠÙ„Ù‚Ø§Ù‡Ø§ Ø±Ø§Ø­Øª Ø¯Ø±Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>,Ù†. Ù… Ø¨Ø¥Ù„Ø­Ø§Ø­ Ùˆ Ø¨ÙƒÙ„ Ø±ÙˆØ­ ÙˆØ·Ù†ÙŠØ© Ù†.Ù… Ù†. Ù… Ù†. Ù…</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ù† Ù… Ø¨Ø¥Ù„Ø­Ø§Ø­ Ø¨ÙƒÙ„ Ø±ÙˆØ­ ÙˆØ·Ù†ÙŠØ© Ù… Ù… Ù…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>Ø®Ù„ÙŠ Ø±Ø§Ù†ÙŠ ØµØ§ÙŠÙ… Ù…ÙˆØ± ÙØ·ÙˆØ± Ù†Ø´Ø§ Ø§Ù„Ù„Ù‡ Ù†ØªÙ‡Ù„Ø§</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø®Ù„ÙŠ Ø±Ø§Ù†ÙŠ ØµØ§ÙŠÙ… Ù…ÙˆØ± ÙØ·ÙˆØ± Ù†Ø´Ø§ Ø§Ù„Ù‡ Ù†ØªÙ‡Ù„Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>Ù‡Ø°ÙŠ Ø·Ù„Ù‚ØªÙˆÙ‡Ø§ ÙŠØ§Ù…Ø§Øª Ù„ÙˆÙ„Ø© ØªØ¹ Ø¨Ø§Ùƒ Ù‡Ø°Ø§ ÙˆÙŠÙ† ÙØ§ØªØª pub...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø·Ù„Ù‚ØªÙˆÙ‡Ø§ ÙŠØ§Ù…Ø§Øª Ù„ÙˆÙ„Ø© Ø¨Ø§Ùƒ ÙØ§Øª publication ØªØ¹ÙƒÙ… Ø´Ø±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>Ù†Ø®Ù„Ø© Ù‡Ø°ÙŠÙƒ ØªØ§Ø¹ Ø´Ø·ÙŠØ­ ÙˆØ±Ø·ÙŠØ­ Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø®Ø§Ø·ÙŠ Ù‚Ø§Ø¹ Ø¨ÙˆØ¨...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ù†Ø®Ù„Ø© Ù‡Ø°ÙŠÙƒ Ø´Ø·ÙŠØ­ ÙˆØ±Ø·ÙŠØ­ Ù‡ Ø®Ø§Ø·ÙŠ Ù‚Ø§Ø¹ Ø¨ÙˆØ¨Ø¬ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>Nik ymah l9hba li b9a ychri djezzy ynik mo ykh...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Nik ymah l9hba li b9a ychri djezy ynik mo ykhl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>Ani bgratwi yzbi flixsit dawhomli  djezzy ta3 zbi</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Ani bgratwi yzbi flixsit dawhomli djezy ta3 zbi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>Dirolna free fire ğŸ˜­</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dirolna fre fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>ØµØ­Ø§ Ù„ÙŠÙ†Ø¯ÙŠÙ†linkdedln  Ø«Ø§Ù†ÙŠ ÙŠØªØ±ÙŠØ´Ùˆ Ø¨ÙŠÙ‡</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ØµØ­Ø§ Ù„ÙŠÙ†Ø¯ÙŠÙ†linkdedln Ø«Ø§Ù†ÙŠ ÙŠØªØ±ÙŠØ´Ùˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>Ø¯Ø¬ÙŠØ²ÙŠ Ø£Ø³ÙˆØ£ Ø´Ø¨ÙƒØ©</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø¯Ø¬ÙŠØ²ÙŠ Ø£Ø³ÙˆØ£ Ø´Ø¨ÙƒØ©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>ÙˆØ§Ù†Ø§ ÙˆÙ‚ØªØ§Ø´ ØªØ±ÙŠØ¨ÙˆÙ†Ø¯ÙŠÙˆ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„ØªÙŠ Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Øµ /:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ÙˆØ§Ù†Ø§ ÙˆÙ‚ØªØ§Ø´ ØªØ±ÙŠØ¨ÙˆÙ†Ø¯ÙŠÙˆ Ø±Ø³Ø§Ù„ØªÙŠ Ø§Ù„Ø®Ø§Øµ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <td>Ø´ÙƒÙˆÙ† Ù‚Ø§Ù„ÙƒÙ… Ø±Ø§Ù†Ø§ ØµØ§Ø¨Ø±ÙŠÙ†</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø´ÙƒÙˆÙ† Ù‚Ø§Ù„ÙƒÙ… ØµØ§Ø¨Ø±ÙŠÙ†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>Ø§ÙƒÙŠØ¯ Ù…Ø§ Ø­Ø¨Ø´ ÙŠØ±Ø¬Ø¹ Ø§Ù„Ø£Ù…ÙˆØ§Ù„ Ø§Ù„Ù…Ù†Ù‡ÙˆØ¨Ø© Ø§Ù„ØªÙŠ ÙŠÙ†ØªØ¸Ø±Ù‡Ø§...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ø§ÙƒÙŠØ¯ Ø­Ø¨Ø´ ÙŠØ±Ø¬Ø¹ Ø§Ù„Ø£Ù…ÙˆØ§Ù„ Ø§Ù„Ù…Ù†Ù‡ÙˆØ¨Ø© ÙŠÙ†ØªØ¸Ø±Ù‡Ø§ Ø¨ÙˆØµØ¨Ø¹ Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>Ø´Ø­Ø§Ù„ Ø®Ù„ØµÙˆÙƒ Ù…ÙˆØ¨Ù„ÙŠØ³</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø´Ø­Ø§Ù„ Ø®Ù„ØµÙˆÙƒ Ù…ÙˆØ¨Ù„ÙŠØ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø§Ø¬Ø¹Ù„ Ø¹ÙŠØ´ØªÙ†Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¨Ù„Ø§Ø¯ ØªØ®ÙÙŠÙ Ø°Ù†ÙˆØ¨</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø§Ù„Ù‡Ù… Ø§Ø¬Ø¹Ù„ Ø¹ÙŠØ´ØªÙ†Ø§ Ø§Ù„Ø¨Ù„Ø§Ø¯ ØªØ®ÙÙŠÙ Ø°Ù†ÙˆØ¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7406</th>\n",
       "      <td>ÙˆÙ†Ø¯ÙŠØ±Ù‡Ø§ Ø¨Ø§Ù‡ Ù†Ù„Ø¹Ø¨ ØªØ§Ø¹ Ø¯ÙŠÙ†ØµÙˆØ± Ù‡Ø¯ÙŠÙƒ ÙˆÙ„Ø§ ÙƒÙŠÙØ§Ù‡ Ù†ØªÙˆ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ÙˆÙ†Ø¯ÙŠØ±Ù‡Ø§ Ø¨Ø§Ù‡ Ù†Ù„Ø¹Ø¨ Ø¯ÙŠÙ†ØµÙˆØ± Ù†ØªÙˆÙ… ÙˆÙ‚ØªØ§Ø´ ØªØ­Ø³Ù†Ùˆ Ø§Ù„Ø®Ø¯Ù…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8948</th>\n",
       "      <td>Thabou tsem3ouhom ya rkhas ah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thabou tsem3ouhom ya rkhas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7571</th>\n",
       "      <td>Ù‚Ø¯Ù…Øª Ø´ÙƒÙˆÙ‰ Ø¹Ù„Ù‰ Ø³ÙˆØ¡ Ø§Ù„Ø®Ø¯Ù…Ø© ÙˆØ¶Ø¹Ù Ø§Ù„Ø´Ø¨ÙƒØ© ÙÙ„Ù… Ù†ØªÙ„Ù‚Ù‰...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ù‚Ø¯Ù…Øª Ø´ÙƒÙˆÙ‰ Ø³ÙˆØ¡ Ø§Ù„Ø®Ø¯Ù…Ø© ÙˆØ¶Ø¹Ù Ø§Ù„Ø´Ø¨ÙƒØ© ÙÙ„Ù… Ù†ØªÙ„Ù‚Ù‰ Ø§Ù„Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6955</th>\n",
       "      <td>Ø§Ù„Ù…ØºØ±Ø¨ ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ ÙØ§ÙŠÙ‚ Ù„ÙŠÙƒ Ù…Ù† Ø§Ù„Ù†Ø¹Ø§Ø³ Ø§Ø³ÙŠ ØªØ¨ÙˆÙ† Ø§Ù„...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ø§Ù„Ù…ØºØ±Ø¨ ÙˆØ§Ù„Ù‡ ÙØ§ÙŠÙ‚ Ø§Ù„Ù†Ø¹Ø§Ø³ Ø§Ø³ÙŠ ØªØ¨ÙˆÙ† Ø§Ù„Ø¹Ø§Ù… Ø¬Ø§ ÙŠÙ„Ù‚Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>ÙˆØ¹Ù„Ø§Ø´ ÙƒÙˆÙ†ÙƒØ³ÙŠÙˆ ØªØ§Ø¹ÙƒÙ… ØªÙ‚ÙŠÙ„ ØªØ¹Ø§ÙŠÙˆ Ø±Ø§Ù‡Ø¬</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ÙˆØ¹Ù„Ø§Ø´ ÙƒÙˆÙ†ÙƒØ³ÙŠÙˆ ØªØ§Ø¹ÙƒÙ… ØªÙ‚ÙŠÙ„ ØªØ¹Ø§ÙŠÙˆ Ø±Ø§Ù‡Ø¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>Ø±Ø§Ùƒ Ø«Ù‚ÙŠÙ„Ø© Ø¬ÙŠØ²ÙŠ Ù†Ø´Ø§Ù„Ù‡ ØªÙˆÙ„Ø¯ÙŠ Ø¨Ø£Ù‚Ø±Ø¨ ÙˆÙ‚ØªğŸ™‚</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø«Ù‚ÙŠÙ„Ø© Ø¬ÙŠØ²ÙŠ Ù†Ø´Ø§Ù„Ù‡ ØªÙˆÙ„Ø¯ÙŠ Ø¨Ø£Ù‚Ø±Ø¨ ÙˆÙ‚Øª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7060</th>\n",
       "      <td>Ø¨Ø¯Ù„ Ø§Ù„Ø´Ø¹Ø§Ø± ÙˆØ±Ø¯Ù‡ 50Ø¬ÙŠØ¬Ø§ Ø·ÙˆÙ†ÙŠÙƒØªÙŠ ÙˆØ­Ø¯Ùƒ ÙˆÙ…Ù†Ø¹ Ø£ØµØ¯Ù‚Ø§...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø¨Ø¯Ù„ Ø§Ù„Ø´Ø¹Ø§Ø± ÙˆØ±Ø¯Ù‡ 50Ø¬ÙŠØ¬Ø§ Ø·ÙˆÙ†ÙŠÙƒØªÙŠ ÙˆØ­Ø¯Ùƒ ÙˆÙ…Ù†Ø¹ Ø£ØµØ¯Ù‚Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9184</th>\n",
       "      <td>Ø§ÙŠÙ† Ø±ÙŠØ²Ùˆ Ø§Ù†Ø§ Ù„Ø§ Ø§Ø±Ø§Ù‡ ÙŠØ§Ø§Ùˆ Ù„ÙƒÙˆÙ†ÙƒØ³ÙŠÙˆ Ø±Ø§Ø­Øª ÙŠØ§ Ø¬ÙŠØ²...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ø§ÙŠÙ† Ø±ÙŠØ²Ùˆ Ø§Ø±Ø§Ù‡ ÙŠØ§Ùˆ Ù„ÙƒÙˆÙ†ÙƒØ³ÙŠÙˆ Ø±Ø§Ø­Øª Ø¬ÙŠØ²ÙŠ Ø®ÙˆÙŠØ§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>ğŸŒğŸŒğŸŒğŸŒğŸŒğŸŒğŸŒğŸŒ</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  class  \\\n",
       "4042                             Ø³ÙƒØª Ø¯Ù‡Ø±Ø§Ù‹ .. ÙˆÙ†Ø·Ù‚ ÙƒÙØ±Ø§Ù‹    NaN   \n",
       "796    Ø³Ø±Ø§Ù‚ ÙŠÙÙ„ÙŠÙƒØ³ÙŠ Ù„ÙˆØ§Ø­Ø¯ ÙŠØ¬ÙŠ ÙŠØ§ÙƒØªÙŠÙÙŠ ÙŠÙ„Ù‚Ø§Ù‡Ø§ Ø±Ø§Ø­Øª Ø¯Ø±Ø§...    NaN   \n",
       "9875          ,Ù†. Ù… Ø¨Ø¥Ù„Ø­Ø§Ø­ Ùˆ Ø¨ÙƒÙ„ Ø±ÙˆØ­ ÙˆØ·Ù†ÙŠØ© Ù†.Ù… Ù†. Ù… Ù†. Ù…    NaN   \n",
       "6274             Ø®Ù„ÙŠ Ø±Ø§Ù†ÙŠ ØµØ§ÙŠÙ… Ù…ÙˆØ± ÙØ·ÙˆØ± Ù†Ø´Ø§ Ø§Ù„Ù„Ù‡ Ù†ØªÙ‡Ù„Ø§      NaN   \n",
       "4343   Ù‡Ø°ÙŠ Ø·Ù„Ù‚ØªÙˆÙ‡Ø§ ÙŠØ§Ù…Ø§Øª Ù„ÙˆÙ„Ø© ØªØ¹ Ø¨Ø§Ùƒ Ù‡Ø°Ø§ ÙˆÙŠÙ† ÙØ§ØªØª pub...    NaN   \n",
       "5161   Ù†Ø®Ù„Ø© Ù‡Ø°ÙŠÙƒ ØªØ§Ø¹ Ø´Ø·ÙŠØ­ ÙˆØ±Ø·ÙŠØ­ Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø®Ø§Ø·ÙŠ Ù‚Ø§Ø¹ Ø¨ÙˆØ¨...    NaN   \n",
       "4017   Nik ymah l9hba li b9a ychri djezzy ynik mo ykh...   -1.0   \n",
       "2041   Ani bgratwi yzbi flixsit dawhomli  djezzy ta3 zbi   -1.0   \n",
       "4169                                 Dirolna free fire ğŸ˜­    NaN   \n",
       "2556                ØµØ­Ø§ Ù„ÙŠÙ†Ø¯ÙŠÙ†linkdedln  Ø«Ø§Ù†ÙŠ ÙŠØªØ±ÙŠØ´Ùˆ Ø¨ÙŠÙ‡    NaN   \n",
       "6837                                     Ø¯Ø¬ÙŠØ²ÙŠ Ø£Ø³ÙˆØ£ Ø´Ø¨ÙƒØ©    NaN   \n",
       "641       ÙˆØ§Ù†Ø§ ÙˆÙ‚ØªØ§Ø´ ØªØ±ÙŠØ¨ÙˆÙ†Ø¯ÙŠÙˆ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„ØªÙŠ Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Øµ /:    NaN   \n",
       "10039                             Ø´ÙƒÙˆÙ† Ù‚Ø§Ù„ÙƒÙ… Ø±Ø§Ù†Ø§ ØµØ§Ø¨Ø±ÙŠÙ†    NaN   \n",
       "6045   Ø§ÙƒÙŠØ¯ Ù…Ø§ Ø­Ø¨Ø´ ÙŠØ±Ø¬Ø¹ Ø§Ù„Ø£Ù…ÙˆØ§Ù„ Ø§Ù„Ù…Ù†Ù‡ÙˆØ¨Ø© Ø§Ù„ØªÙŠ ÙŠÙ†ØªØ¸Ø±Ù‡Ø§...    1.0   \n",
       "4885                                   Ø´Ø­Ø§Ù„ Ø®Ù„ØµÙˆÙƒ Ù…ÙˆØ¨Ù„ÙŠØ³    NaN   \n",
       "6816          Ø§Ù„Ù„Ù‡Ù… Ø§Ø¬Ø¹Ù„ Ø¹ÙŠØ´ØªÙ†Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¨Ù„Ø§Ø¯ ØªØ®ÙÙŠÙ Ø°Ù†ÙˆØ¨    NaN   \n",
       "7406   ÙˆÙ†Ø¯ÙŠØ±Ù‡Ø§ Ø¨Ø§Ù‡ Ù†Ù„Ø¹Ø¨ ØªØ§Ø¹ Ø¯ÙŠÙ†ØµÙˆØ± Ù‡Ø¯ÙŠÙƒ ÙˆÙ„Ø§ ÙƒÙŠÙØ§Ù‡ Ù†ØªÙˆ...    NaN   \n",
       "8948                       Thabou tsem3ouhom ya rkhas ah    NaN   \n",
       "7571   Ù‚Ø¯Ù…Øª Ø´ÙƒÙˆÙ‰ Ø¹Ù„Ù‰ Ø³ÙˆØ¡ Ø§Ù„Ø®Ø¯Ù…Ø© ÙˆØ¶Ø¹Ù Ø§Ù„Ø´Ø¨ÙƒØ© ÙÙ„Ù… Ù†ØªÙ„Ù‚Ù‰...    NaN   \n",
       "6955   Ø§Ù„Ù…ØºØ±Ø¨ ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ ÙØ§ÙŠÙ‚ Ù„ÙŠÙƒ Ù…Ù† Ø§Ù„Ù†Ø¹Ø§Ø³ Ø§Ø³ÙŠ ØªØ¨ÙˆÙ† Ø§Ù„...    1.0   \n",
       "825                  ÙˆØ¹Ù„Ø§Ø´ ÙƒÙˆÙ†ÙƒØ³ÙŠÙˆ ØªØ§Ø¹ÙƒÙ… ØªÙ‚ÙŠÙ„ ØªØ¹Ø§ÙŠÙˆ Ø±Ø§Ù‡Ø¬   -1.0   \n",
       "2612               Ø±Ø§Ùƒ Ø«Ù‚ÙŠÙ„Ø© Ø¬ÙŠØ²ÙŠ Ù†Ø´Ø§Ù„Ù‡ ØªÙˆÙ„Ø¯ÙŠ Ø¨Ø£Ù‚Ø±Ø¨ ÙˆÙ‚ØªğŸ™‚    NaN   \n",
       "7060   Ø¨Ø¯Ù„ Ø§Ù„Ø´Ø¹Ø§Ø± ÙˆØ±Ø¯Ù‡ 50Ø¬ÙŠØ¬Ø§ Ø·ÙˆÙ†ÙŠÙƒØªÙŠ ÙˆØ­Ø¯Ùƒ ÙˆÙ…Ù†Ø¹ Ø£ØµØ¯Ù‚Ø§...    NaN   \n",
       "9184   Ø§ÙŠÙ† Ø±ÙŠØ²Ùˆ Ø§Ù†Ø§ Ù„Ø§ Ø§Ø±Ø§Ù‡ ÙŠØ§Ø§Ùˆ Ù„ÙƒÙˆÙ†ÙƒØ³ÙŠÙˆ Ø±Ø§Ø­Øª ÙŠØ§ Ø¬ÙŠØ²...    NaN   \n",
       "5982                                            ğŸŒğŸŒğŸŒğŸŒğŸŒğŸŒğŸŒğŸŒ    NaN   \n",
       "\n",
       "                                          comments_clean  \n",
       "4042                                 Ø³ÙƒØª Ø¯Ù‡Ø±Ø§ ÙˆÙ†Ø·Ù‚ ÙƒÙØ±Ø§   \n",
       "796    Ø³Ø±Ø§Ù‚ ÙŠÙÙ„ÙŠÙƒØ³ÙŠ Ù„ÙˆØ§Ø­Ø¯ ÙŠØ¬ÙŠ ÙŠØ§ÙƒØªÙŠÙÙŠ ÙŠÙ„Ù‚Ø§Ù‡Ø§ Ø±Ø§Ø­Øª Ø¯Ø±Ø§...  \n",
       "9875                      Ù† Ù… Ø¨Ø¥Ù„Ø­Ø§Ø­ Ø¨ÙƒÙ„ Ø±ÙˆØ­ ÙˆØ·Ù†ÙŠØ© Ù… Ù… Ù…  \n",
       "6274                Ø®Ù„ÙŠ Ø±Ø§Ù†ÙŠ ØµØ§ÙŠÙ… Ù…ÙˆØ± ÙØ·ÙˆØ± Ù†Ø´Ø§ Ø§Ù„Ù‡ Ù†ØªÙ‡Ù„Ø§  \n",
       "4343   Ø·Ù„Ù‚ØªÙˆÙ‡Ø§ ÙŠØ§Ù…Ø§Øª Ù„ÙˆÙ„Ø© Ø¨Ø§Ùƒ ÙØ§Øª publication ØªØ¹ÙƒÙ… Ø´Ø±...  \n",
       "5161               Ù†Ø®Ù„Ø© Ù‡Ø°ÙŠÙƒ Ø´Ø·ÙŠØ­ ÙˆØ±Ø·ÙŠØ­ Ù‡ Ø®Ø§Ø·ÙŠ Ù‚Ø§Ø¹ Ø¨ÙˆØ¨Ø¬ÙŠ  \n",
       "4017   Nik ymah l9hba li b9a ychri djezy ynik mo ykhl...  \n",
       "2041     Ani bgratwi yzbi flixsit dawhomli djezy ta3 zbi  \n",
       "4169                                    Dirolna fre fire  \n",
       "2556                     ØµØ­Ø§ Ù„ÙŠÙ†Ø¯ÙŠÙ†linkdedln Ø«Ø§Ù†ÙŠ ÙŠØªØ±ÙŠØ´Ùˆ  \n",
       "6837                                     Ø¯Ø¬ÙŠØ²ÙŠ Ø£Ø³ÙˆØ£ Ø´Ø¨ÙƒØ©  \n",
       "641                   ÙˆØ§Ù†Ø§ ÙˆÙ‚ØªØ§Ø´ ØªØ±ÙŠØ¨ÙˆÙ†Ø¯ÙŠÙˆ Ø±Ø³Ø§Ù„ØªÙŠ Ø§Ù„Ø®Ø§Øµ   \n",
       "10039                                  Ø´ÙƒÙˆÙ† Ù‚Ø§Ù„ÙƒÙ… ØµØ§Ø¨Ø±ÙŠÙ†  \n",
       "6045   Ø§ÙƒÙŠØ¯ Ø­Ø¨Ø´ ÙŠØ±Ø¬Ø¹ Ø§Ù„Ø£Ù…ÙˆØ§Ù„ Ø§Ù„Ù…Ù†Ù‡ÙˆØ¨Ø© ÙŠÙ†ØªØ¸Ø±Ù‡Ø§ Ø¨ÙˆØµØ¨Ø¹ Ù„...  \n",
       "4885                                   Ø´Ø­Ø§Ù„ Ø®Ù„ØµÙˆÙƒ Ù…ÙˆØ¨Ù„ÙŠØ³  \n",
       "6816                  Ø§Ù„Ù‡Ù… Ø§Ø¬Ø¹Ù„ Ø¹ÙŠØ´ØªÙ†Ø§ Ø§Ù„Ø¨Ù„Ø§Ø¯ ØªØ®ÙÙŠÙ Ø°Ù†ÙˆØ¨  \n",
       "7406   ÙˆÙ†Ø¯ÙŠØ±Ù‡Ø§ Ø¨Ø§Ù‡ Ù†Ù„Ø¹Ø¨ Ø¯ÙŠÙ†ØµÙˆØ± Ù†ØªÙˆÙ… ÙˆÙ‚ØªØ§Ø´ ØªØ­Ø³Ù†Ùˆ Ø§Ù„Ø®Ø¯Ù…...  \n",
       "8948                          Thabou tsem3ouhom ya rkhas  \n",
       "7571   Ù‚Ø¯Ù…Øª Ø´ÙƒÙˆÙ‰ Ø³ÙˆØ¡ Ø§Ù„Ø®Ø¯Ù…Ø© ÙˆØ¶Ø¹Ù Ø§Ù„Ø´Ø¨ÙƒØ© ÙÙ„Ù… Ù†ØªÙ„Ù‚Ù‰ Ø§Ù„Ø§...  \n",
       "6955   Ø§Ù„Ù…ØºØ±Ø¨ ÙˆØ§Ù„Ù‡ ÙØ§ÙŠÙ‚ Ø§Ù„Ù†Ø¹Ø§Ø³ Ø§Ø³ÙŠ ØªØ¨ÙˆÙ† Ø§Ù„Ø¹Ø§Ù… Ø¬Ø§ ÙŠÙ„Ù‚Ø§...  \n",
       "825                  ÙˆØ¹Ù„Ø§Ø´ ÙƒÙˆÙ†ÙƒØ³ÙŠÙˆ ØªØ§Ø¹ÙƒÙ… ØªÙ‚ÙŠÙ„ ØªØ¹Ø§ÙŠÙˆ Ø±Ø§Ù‡Ø¬  \n",
       "2612                    Ø«Ù‚ÙŠÙ„Ø© Ø¬ÙŠØ²ÙŠ Ù†Ø´Ø§Ù„Ù‡ ØªÙˆÙ„Ø¯ÙŠ Ø¨Ø£Ù‚Ø±Ø¨ ÙˆÙ‚Øª  \n",
       "7060   Ø¨Ø¯Ù„ Ø§Ù„Ø´Ø¹Ø§Ø± ÙˆØ±Ø¯Ù‡ 50Ø¬ÙŠØ¬Ø§ Ø·ÙˆÙ†ÙŠÙƒØªÙŠ ÙˆØ­Ø¯Ùƒ ÙˆÙ…Ù†Ø¹ Ø£ØµØ¯Ù‚Ø§...  \n",
       "9184           Ø§ÙŠÙ† Ø±ÙŠØ²Ùˆ Ø§Ø±Ø§Ù‡ ÙŠØ§Ùˆ Ù„ÙƒÙˆÙ†ÙƒØ³ÙŠÙˆ Ø±Ø§Ø­Øª Ø¬ÙŠØ²ÙŠ Ø®ÙˆÙŠØ§  \n",
       "5982                                                      "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments_clean'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIGNETWORK\\AppData\\Local\\Temp\\ipykernel_13008\\3493959318.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['comments_clean'].replace('', np.nan, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments_clean'].replace('', np.nan, inplace=True)\n",
    "missing_values = df[df['comments_clean'].isnull()]\n",
    "#df=df.dropna(subset = ['comments_clean'])\n",
    "len(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset = ['comments_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_det(texte):\n",
    "    langage = detect(texte)\n",
    "    if langage not in ['en','fr']:\n",
    "        langage = 'dz'\n",
    "    \n",
    "    return langage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n"
     ]
    }
   ],
   "source": [
    "text ='3andkom cnx ma9wda bzfffffff ou rizo bal m nhki'\n",
    "print(lang_det(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFXLMRobertaForSequenceClassification were initialized from the model checkpoint at papluca/xlm-roberta-base-language-detection.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n"
     ]
    }
   ],
   "source": [
    "# Load the language detection pipeline\n",
    "lang_detect = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "# Text to classify\n",
    "text = \"Pourquoi vous limitez le dÃ©bit ?.\"\n",
    "\n",
    "# Run the language detection pipeline\n",
    "result = lang_detect(text)\n",
    "\n",
    "# Print the detected language\n",
    "print(result[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n"
     ]
    }
   ],
   "source": [
    "# Text to classify\n",
    "text = \"Ú¨Ø§Ø¹ Ù…Ø§Ø´ÙŠ conection surtout les environ ta3 sedikia\"\n",
    "\n",
    "# Run the language detection pipeline\n",
    "result = lang_detect(text)\n",
    "\n",
    "# Print the detected language\n",
    "print(result[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "# Utilisation de la mÃ©thode SequenceMatcher pour calculer la similaritÃ© entre deux chaÃ®nes de caractÃ¨res\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "def detecter_langage(texte):\n",
    "    # DÃ©tection de la langue avec langdetect\n",
    "    langage = detect(texte)\n",
    "    \n",
    "   #  Si le texte est similaire Ã  l'anglais, au franÃ§ais ou Ã  l'arabe, il est classÃ© comme dialecte algÃ©rien\n",
    "    if langage in ['en', 'fr', 'ar']:\n",
    "        similarites = {\n",
    "            'en': similar(texte, 'english'),\n",
    "            'fr': similar(texte, 'franÃ§ais'),\n",
    "            'ar': similar(texte, 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©')\n",
    "        }\n",
    "        # Le texte est classÃ© comme dialecte algÃ©rien s'il est plus similaire Ã  une de ces langues qu'Ã  l'autre\n",
    "        if max(similarites.values()) == similarites[langage] or langage =='so':\n",
    "            langage = 'dz'\n",
    "    \n",
    "    return langage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr\n"
     ]
    }
   ],
   "source": [
    "txt = \"Kanet 3endi beseh rÃ©seau fiha mekhsous bezaf f la willaya de Tizi ouzou apart le centre ville makanch rÃ©seau\"\n",
    "print(detecter_langage(txt))\n",
    "  #  df['len'] = df['comments_nett'].apply(detecter_langage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIGNETWORK\\AppData\\Local\\Temp\\ipykernel_13008\\2026574333.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.at[index, 'language'] = result[0]['label']\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text = str(row['comments_clean'])\n",
    "    if text:\n",
    "        try:\n",
    "            result = lang_detect(text)\n",
    "            df.at[index, 'language'] = result[0]['label']\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
